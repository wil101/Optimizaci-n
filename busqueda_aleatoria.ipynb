{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f37b0a",
   "metadata": {},
   "source": [
    "# MÃ©todo de BÃºsqueda Aleatoria (Random Search)\n",
    "## OptimizaciÃ³n estocÃ¡stica para encontrar mÃ¡ximos y mÃ­nimos locales\n",
    "\n",
    "La bÃºsqueda aleatoria es un mÃ©todo de optimizaciÃ³n global que explora el espacio de bÃºsqueda mediante muestreo aleatorio uniforme. Es especialmente Ãºtil cuando:\n",
    "- La funciÃ³n objetivo es multimodal (tiene varios extremos locales)\n",
    "- No se dispone de informaciÃ³n sobre gradientes\n",
    "- Se busca una soluciÃ³n rÃ¡pida y robusta\n",
    "\n",
    "**Ventajas:**\n",
    "- Simple de implementar\n",
    "- No requiere derivadas\n",
    "- Buena exploraciÃ³n global\n",
    "- Robusto ante ruido\n",
    "\n",
    "**Desventajas:**\n",
    "- Convergencia lenta\n",
    "- No garantiza encontrar el Ã³ptimo global\n",
    "- Requiere muchas evaluaciones de funciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: ImportaciÃ³n de librerÃ­as\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from typing import Callable, Tuple, Optional\n",
    "\n",
    "# ConfiguraciÃ³n para mejores grÃ¡ficas\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")\n",
    "print(f\"ğŸ“Š Numpy versiÃ³n: {np.__version__}\")\n",
    "print(f\"ğŸ“ˆ Matplotlib backend: {plt.get_backend()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54529ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Funciones auxiliares de validaciÃ³n\n",
    "def validar_entradas(func: Callable, a: float, b: float, n_iter: int, find_max: bool) -> None:\n",
    "    \"\"\"\n",
    "    Valida los parÃ¡metros de entrada para el mÃ©todo de bÃºsqueda aleatoria.\n",
    "    \n",
    "    Args:\n",
    "        func: FunciÃ³n objetivo a optimizar\n",
    "        a: LÃ­mite inferior del intervalo\n",
    "        b: LÃ­mite superior del intervalo  \n",
    "        n_iter: NÃºmero de iteraciones\n",
    "        find_max: Si buscar mÃ¡ximo (True) o mÃ­nimo (False)\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Si algÃºn parÃ¡metro es invÃ¡lido\n",
    "        TypeError: Si func no es callable\n",
    "    \"\"\"\n",
    "    if not callable(func):\n",
    "        raise TypeError(\"El parÃ¡metro 'func' debe ser una funciÃ³n callable\")\n",
    "    \n",
    "    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\n",
    "        raise TypeError(\"Los lÃ­mites 'a' y 'b' deben ser nÃºmeros\")\n",
    "    \n",
    "    if a >= b:\n",
    "        raise ValueError(f\"El lÃ­mite inferior 'a' ({a}) debe ser menor que 'b' ({b})\")\n",
    "    \n",
    "    if not isinstance(n_iter, int) or n_iter <= 0:\n",
    "        raise ValueError(f\"El nÃºmero de iteraciones debe ser un entero positivo, recibido: {n_iter}\")\n",
    "    \n",
    "    if not isinstance(find_max, bool):\n",
    "        raise TypeError(\"El parÃ¡metro 'find_max' debe ser booleano (True/False)\")\n",
    "    \n",
    "    # Validar que la funciÃ³n sea evaluable en el intervalo\n",
    "    try:\n",
    "        test_points = [a, (a + b) / 2, b]\n",
    "        for point in test_points:\n",
    "            result = func(point)\n",
    "            if not isinstance(result, (int, float)) or np.isnan(result) or np.isinf(result):\n",
    "                raise ValueError(f\"La funciÃ³n devuelve un valor invÃ¡lido en x={point}: {result}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error al evaluar la funciÃ³n en el intervalo [{a}, {b}]: {str(e)}\")\n",
    "\n",
    "def detectar_funcion_constante(func: Callable, a: float, b: float, n_muestras: int = 20) -> bool:\n",
    "    \"\"\"\n",
    "    Detecta si una funciÃ³n es aproximadamente constante en un intervalo.\n",
    "    \n",
    "    Args:\n",
    "        func: FunciÃ³n a evaluar\n",
    "        a, b: LÃ­mites del intervalo\n",
    "        n_muestras: NÃºmero de puntos a muestrear\n",
    "    \n",
    "    Returns:\n",
    "        True si la funciÃ³n parece constante, False en caso contrario\n",
    "    \"\"\"\n",
    "    x_test = np.linspace(a, b, n_muestras)\n",
    "    y_test = [func(x) for x in x_test]\n",
    "    varianza = np.var(y_test)\n",
    "    return varianza < 1e-10\n",
    "\n",
    "print(\"âœ… Funciones de validaciÃ³n definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54decf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: ImplementaciÃ³n principal del mÃ©todo de bÃºsqueda aleatoria\n",
    "def random_search(func: Callable, \n",
    "                 a: Optional[float] = None, \n",
    "                 b: Optional[float] = None, \n",
    "                 n_iter: int = 1000, \n",
    "                 find_max: bool = True,\n",
    "                 semilla: Optional[int] = None,\n",
    "                 mostrar_progreso: bool = True) -> Tuple[float, float, pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Implementa el mÃ©todo de bÃºsqueda aleatoria para optimizaciÃ³n de funciones unidimensionales.\n",
    "    \n",
    "    Args:\n",
    "        func: FunciÃ³n objetivo a optimizar\n",
    "        a: LÃ­mite inferior del intervalo (None para usar valores por defecto)\n",
    "        b: LÃ­mite superior del intervalo (None para usar valores por defecto)\n",
    "        n_iter: NÃºmero de iteraciones aleatorias (default: 1000)\n",
    "        find_max: Si buscar mÃ¡ximo (True) o mÃ­nimo (False) (default: True)\n",
    "        semilla: Semilla para reproducibilidad (opcional)\n",
    "        mostrar_progreso: Si mostrar informaciÃ³n durante la ejecuciÃ³n\n",
    "    \n",
    "    Returns:\n",
    "        Tupla con (x_optimo, f_optimo, tabla_iteraciones, estadisticas)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configurar semilla para reproducibilidad\n",
    "    if semilla is not None:\n",
    "        np.random.seed(semilla)\n",
    "    \n",
    "    # Usar valores por defecto si no se especifican lÃ­mites\n",
    "    if a is None or b is None:\n",
    "        if mostrar_progreso:\n",
    "            print(\"ğŸ” Usando intervalo por defecto [-5, 5]\")\n",
    "        a, b = -5.0, 5.0\n",
    "    \n",
    "    # Validar entradas\n",
    "    validar_entradas(func, a, b, n_iter, find_max)\n",
    "    \n",
    "    # Detectar funciÃ³n constante y advertir\n",
    "    if detectar_funcion_constante(func, a, b):\n",
    "        tipo_busqueda = \"mÃ¡ximo\" if find_max else \"mÃ­nimo\"\n",
    "        warnings.warn(f\"âš ï¸  La funciÃ³n parece ser constante en [{a}, {b}]. \"\n",
    "                     f\"Buscar {tipo_busqueda} puede no ser significativo.\", UserWarning)\n",
    "    \n",
    "    # Inicializar variables\n",
    "    tiempo_inicio = time.time()\n",
    "    \n",
    "    # Listas para almacenar resultados\n",
    "    iteraciones = []\n",
    "    x_aleatorios = []\n",
    "    valores_funcion = []\n",
    "    mejores_hasta_ahora = []\n",
    "    \n",
    "    # Inicializar con el primer punto aleatorio\n",
    "    x_optimo = np.random.uniform(a, b)\n",
    "    f_optimo = func(x_optimo)\n",
    "    actualizaciones_optimo = 1\n",
    "    \n",
    "    # Bucle principal de bÃºsqueda aleatoria\n",
    "    for i in range(n_iter):\n",
    "        # Generar punto aleatorio uniforme en [a, b]\n",
    "        x_random = np.random.uniform(a, b)\n",
    "        f_random = func(x_random)\n",
    "        \n",
    "        # Actualizar Ã³ptimo segÃºn el tipo de bÃºsqueda\n",
    "        if find_max:\n",
    "            if f_random > f_optimo:\n",
    "                x_optimo, f_optimo = x_random, f_random\n",
    "                actualizaciones_optimo += 1\n",
    "        else:\n",
    "            if f_random < f_optimo:\n",
    "                x_optimo, f_optimo = x_random, f_random\n",
    "                actualizaciones_optimo += 1\n",
    "        \n",
    "        # Registrar iteraciÃ³n\n",
    "        iteraciones.append(i + 1)\n",
    "        x_aleatorios.append(x_random)\n",
    "        valores_funcion.append(f_random)\n",
    "        mejores_hasta_ahora.append(f_optimo)\n",
    "        \n",
    "        # Mostrar progreso cada 20% del total\n",
    "        if mostrar_progreso and (i + 1) % (n_iter // 5) == 0:\n",
    "            porcentaje = (i + 1) / n_iter * 100\n",
    "            tipo = \"mÃ¡x\" if find_max else \"mÃ­n\"\n",
    "            print(f\"ğŸ“Š Progreso: {porcentaje:.0f}% | {tipo} actual: f({x_optimo:.4f}) = {f_optimo:.6f}\")\n",
    "    \n",
    "    tiempo_total = time.time() - tiempo_inicio\n",
    "    \n",
    "    # Crear tabla de iteraciones\n",
    "    tabla = pd.DataFrame({\n",
    "        'IteraciÃ³n': iteraciones,\n",
    "        'x_aleatorio': np.round(x_aleatorios, 6),\n",
    "        'f(x)': np.round(valores_funcion, 6),\n",
    "        'Mejor_hasta_ahora': np.round(mejores_hasta_ahora, 6)\n",
    "    })\n",
    "    \n",
    "    # EstadÃ­sticas de ejecuciÃ³n\n",
    "    estadisticas = {\n",
    "        'tiempo_ejecucion': tiempo_total,\n",
    "        'actualizaciones_optimo': actualizaciones_optimo,\n",
    "        'tasa_mejora': actualizaciones_optimo / n_iter,\n",
    "        'intervalo': (a, b),\n",
    "        'tipo_busqueda': 'mÃ¡ximo' if find_max else 'mÃ­nimo',\n",
    "        'convergencia_final': abs(mejores_hasta_ahora[-1] - mejores_hasta_ahora[-min(100, n_iter):])\n",
    "    }\n",
    "    \n",
    "    if mostrar_progreso:\n",
    "        tipo = \"MÃ¡ximo\" if find_max else \"MÃ­nimo\"\n",
    "        print(f\"\\nğŸ¯ {tipo} encontrado:\")\n",
    "        print(f\"   x* = {x_optimo:.8f}\")\n",
    "        print(f\"   f(x*) = {f_optimo:.8f}\")\n",
    "        print(f\"\\nâ±ï¸  Tiempo de ejecuciÃ³n: {tiempo_total:.4f} segundos\")\n",
    "        print(f\"ğŸ”„ Actualizaciones del Ã³ptimo: {actualizaciones_optimo}/{n_iter} ({estadisticas['tasa_mejora']:.2%})\")\n",
    "    \n",
    "    return x_optimo, f_optimo, tabla, estadisticas\n",
    "\n",
    "print(\"âœ… FunciÃ³n de bÃºsqueda aleatoria implementada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9cc987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: FunciÃ³n de visualizaciÃ³n\n",
    "def graficar_resultados(func: Callable, x_optimo: float, f_optimo: float, \n",
    "                       tabla: pd.DataFrame, estadisticas: dict, \n",
    "                       mostrar_todas_iteraciones: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Crea visualizaciones del proceso de bÃºsqueda aleatoria.\n",
    "    \n",
    "    Args:\n",
    "        func: FunciÃ³n objetivo\n",
    "        x_optimo: Punto Ã³ptimo encontrado\n",
    "        f_optimo: Valor Ã³ptimo de la funciÃ³n\n",
    "        tabla: DataFrame con iteraciones\n",
    "        estadisticas: Diccionario con estadÃ­sticas de ejecuciÃ³n\n",
    "        mostrar_todas_iteraciones: Si mostrar todos los puntos muestreados\n",
    "    \"\"\"\n",
    "    a, b = estadisticas['intervalo']\n",
    "    tipo_busqueda = estadisticas['tipo_busqueda']\n",
    "    \n",
    "    # Crear figura con subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Subplot 1: FunciÃ³n y punto Ã³ptimo\n",
    "    x_continuo = np.linspace(a, b, 1000)\n",
    "    y_continuo = [func(x) for x in x_continuo]\n",
    "    \n",
    "    ax1.plot(x_continuo, y_continuo, 'b-', linewidth=2.5, label='f(x)', alpha=0.8)\n",
    "    \n",
    "    # Marcar el Ã³ptimo encontrado\n",
    "    color_optimo = 'red' if tipo_busqueda == 'mÃ¡ximo' else 'green'\n",
    "    marker_optimo = '^' if tipo_busqueda == 'mÃ¡ximo' else 'v'\n",
    "    ax1.scatter(x_optimo, f_optimo, c=color_optimo, s=200, marker=marker_optimo, \n",
    "               edgecolors='black', linewidth=2, \n",
    "               label=f'{tipo_busqueda.capitalize()}: f({x_optimo:.4f}) = {f_optimo:.6f}',\n",
    "               zorder=5)\n",
    "    \n",
    "    # Mostrar algunos puntos muestreados si se solicita\n",
    "    if mostrar_todas_iteraciones and len(tabla) > 0:\n",
    "        # Mostrar solo una muestra para no saturar la grÃ¡fica\n",
    "        n_mostrar = min(100, len(tabla))\n",
    "        indices_muestra = np.random.choice(len(tabla), n_mostrar, replace=False)\n",
    "        x_muestra = tabla.iloc[indices_muestra]['x_aleatorio']\n",
    "        y_muestra = tabla.iloc[indices_muestra]['f(x)']\n",
    "        ax1.scatter(x_muestra, y_muestra, c='orange', s=10, alpha=0.4, \n",
    "                   label=f'Muestra de {n_mostrar} puntos evaluados')\n",
    "    \n",
    "    ax1.set_xlabel('x', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('f(x)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title(f'BÃºsqueda Aleatoria - {tipo_busqueda.capitalize()} Global\\n'\n",
    "                 f'Intervalo: [{a}, {b}] | Iteraciones: {len(tabla):,}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Convergencia del Ã³ptimo\n",
    "    ax2.plot(tabla['IteraciÃ³n'], tabla['Mejor_hasta_ahora'], 'g-', linewidth=2, \n",
    "            label=f'Convergencia del {tipo_busqueda}')\n",
    "    ax2.axhline(y=f_optimo, color='red', linestyle='--', alpha=0.7, \n",
    "               label=f'Valor final: {f_optimo:.6f}')\n",
    "    \n",
    "    ax2.set_xlabel('IteraciÃ³n', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel(f'Mejor {tipo_busqueda} encontrado', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Convergencia del Algoritmo de BÃºsqueda Aleatoria', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # AÃ±adir estadÃ­sticas como texto\n",
    "    stats_text = (f\"Actualizaciones: {estadisticas['actualizaciones_optimo']} \"\n",
    "                 f\"({estadisticas['tasa_mejora']:.1%})\\n\"\n",
    "                 f\"Tiempo: {estadisticas['tiempo_ejecucion']:.3f}s\")\n",
    "    ax2.text(0.02, 0.98, stats_text, transform=ax2.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            verticalalignment='top', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… FunciÃ³n de visualizaciÃ³n definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Ejemplo 1 - FunciÃ³n cuadrÃ¡tica (bÃºsqueda de mÃ­nimo)\n",
    "print(\"ğŸ”¢ EJEMPLO 1: FunciÃ³n CuadrÃ¡tica - BÃºsqueda de MÃ­nimo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir funciÃ³n cuadrÃ¡tica\n",
    "def funcion_cuadratica(x):\n",
    "    \"\"\"FunciÃ³n cuadrÃ¡tica: f(x) = xÂ² - 4x + 5\"\"\"\n",
    "    return x**2 - 4*x + 5\n",
    "\n",
    "# El mÃ­nimo teÃ³rico estÃ¡ en x = 2, f(2) = 1\n",
    "print(\"ğŸ“ FunciÃ³n: f(x) = xÂ² - 4x + 5\")\n",
    "print(\"ğŸ¯ MÃ­nimo teÃ³rico: x = 2, f(2) = 1\")\n",
    "print(\"ğŸ“ Intervalo de bÃºsqueda: [0, 5]\")\n",
    "print()\n",
    "\n",
    "# Ejecutar bÃºsqueda aleatoria\n",
    "x_min, f_min, tabla_cuadratica, stats_cuadratica = random_search(\n",
    "    func=funcion_cuadratica,\n",
    "    a=0,\n",
    "    b=5,\n",
    "    n_iter=1500,\n",
    "    find_max=False,  # Buscar mÃ­nimo\n",
    "    semilla=42,\n",
    "    mostrar_progreso=True\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Primeras 10 iteraciones:\")\n",
    "print(tabla_cuadratica.head(10))\n",
    "\n",
    "print(\"\\nğŸ“Š Ãšltimas 10 iteraciones:\")\n",
    "print(tabla_cuadratica.tail(10))\n",
    "\n",
    "# Calcular error respecto al Ã³ptimo teÃ³rico\n",
    "error_x = abs(x_min - 2)\n",
    "error_f = abs(f_min - 1)\n",
    "print(f\"\\nğŸ¯ PrecisiÃ³n del resultado:\")\n",
    "print(f\"   Error en x: {error_x:.6f} (teÃ³rico: x = 2)\")\n",
    "print(f\"   Error en f(x): {error_f:.6f} (teÃ³rico: f(x) = 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6: VisualizaciÃ³n del Ejemplo 1\n",
    "print(\"ğŸ“ˆ VisualizaciÃ³n del Ejemplo 1: FunciÃ³n CuadrÃ¡tica\")\n",
    "graficar_resultados(funcion_cuadratica, x_min, f_min, tabla_cuadratica, stats_cuadratica, \n",
    "                   mostrar_todas_iteraciones=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: Ejemplo 2 - FunciÃ³n trigonomÃ©trica compleja (bÃºsqueda de mÃ¡ximo)\n",
    "print(\"ğŸŒŠ EJEMPLO 2: FunciÃ³n TrigonomÃ©trica - BÃºsqueda de MÃ¡ximo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir funciÃ³n trigonomÃ©trica con decaimiento exponencial\n",
    "def funcion_trigonometrica(x):\n",
    "    \"\"\"FunciÃ³n trigonomÃ©trica: f(x) = sin(x) * exp(-x/5)\"\"\"\n",
    "    return np.sin(x) * np.exp(-x/5)\n",
    "\n",
    "print(\"ğŸ“ FunciÃ³n: f(x) = sin(x) * exp(-x/5)\")\n",
    "print(\"ğŸ¯ FunciÃ³n con mÃºltiples mÃ¡ximos locales y decaimiento exponencial\")\n",
    "print(\"ğŸ“ Intervalo de bÃºsqueda: [0, 15]\")\n",
    "print()\n",
    "\n",
    "# Ejecutar bÃºsqueda aleatoria\n",
    "x_max, f_max, tabla_trigonometrica, stats_trigonometrica = random_search(\n",
    "    func=funcion_trigonometrica,\n",
    "    a=0,\n",
    "    b=15,\n",
    "    n_iter=2000,\n",
    "    find_max=True,  # Buscar mÃ¡ximo\n",
    "    semilla=123,\n",
    "    mostrar_progreso=True\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Primeras 10 iteraciones:\")\n",
    "print(tabla_trigonometrica.head(10))\n",
    "\n",
    "print(\"\\nğŸ“Š Ãšltimas 10 iteraciones:\")\n",
    "print(tabla_trigonometrica.tail(10))\n",
    "\n",
    "# El mÃ¡ximo teÃ³rico aproximado estÃ¡ cerca de x â‰ˆ Ï€/2 â‰ˆ 1.571\n",
    "x_teorico = np.pi/2\n",
    "f_teorico = funcion_trigonometrica(x_teorico)\n",
    "print(f\"\\nğŸ¯ ComparaciÃ³n con mÃ¡ximo teÃ³rico aproximado:\")\n",
    "print(f\"   MÃ¡ximo teÃ³rico: x â‰ˆ {x_teorico:.6f}, f(x) â‰ˆ {f_teorico:.6f}\")\n",
    "print(f\"   MÃ¡ximo encontrado: x = {x_max:.6f}, f(x) = {f_max:.6f}\")\n",
    "print(f\"   Diferencia: {abs(f_max - f_teorico):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb220500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8: VisualizaciÃ³n del Ejemplo 2\n",
    "print(\"ğŸ“ˆ VisualizaciÃ³n del Ejemplo 2: FunciÃ³n TrigonomÃ©trica\")\n",
    "graficar_resultados(funcion_trigonometrica, x_max, f_max, tabla_trigonometrica, \n",
    "                   stats_trigonometrica, mostrar_todas_iteraciones=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa22c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9: AnÃ¡lisis comparativo y demostraciÃ³n de personalizaciÃ³n\n",
    "print(\"ğŸ” ANÃLISIS COMPARATIVO: Efectos del nÃºmero de iteraciones\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Definir funciÃ³n de prueba mÃ¡s compleja\n",
    "def funcion_compleja(x):\n",
    "    \"\"\"FunciÃ³n compleja multimodal: f(x) = -xÂ²*sin(5x) + x*cos(3x)\"\"\"\n",
    "    return -x**2 * np.sin(5*x) + x * np.cos(3*x)\n",
    "\n",
    "print(\"ğŸ“ FunciÃ³n de prueba: f(x) = -xÂ²*sin(5x) + x*cos(3x)\")\n",
    "print(\"ğŸ¯ FunciÃ³n multimodal con mÃºltiples extremos locales\")\n",
    "print()\n",
    "\n",
    "# Probar con diferentes nÃºmeros de iteraciones\n",
    "iteraciones_prueba = [100, 500, 1000, 2000]\n",
    "resultados_comparativos = []\n",
    "\n",
    "for n_iter in iteraciones_prueba:\n",
    "    print(f\"ğŸ”„ Probando con {n_iter} iteraciones...\")\n",
    "    \n",
    "    x_opt, f_opt, _, stats = random_search(\n",
    "        func=funcion_compleja,\n",
    "        a=-3,\n",
    "        b=3,\n",
    "        n_iter=n_iter,\n",
    "        find_max=True,\n",
    "        semilla=456,  # Misma semilla para comparaciÃ³n justa\n",
    "        mostrar_progreso=False\n",
    "    )\n",
    "    \n",
    "    resultados_comparativos.append({\n",
    "        'Iteraciones': n_iter,\n",
    "        'x_Ã³ptimo': round(x_opt, 6),\n",
    "        'f_Ã³ptimo': round(f_opt, 6),\n",
    "        'Tiempo(s)': round(stats['tiempo_ejecucion'], 4),\n",
    "        'Actualizaciones': stats['actualizaciones_optimo'],\n",
    "        'Tasa_mejora': f\"{stats['tasa_mejora']:.2%}\"\n",
    "    })\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "df_comparativo = pd.DataFrame(resultados_comparativos)\n",
    "print(\"\\nğŸ“Š Tabla comparativa de resultados:\")\n",
    "print(df_comparativo.to_string(index=False))\n",
    "\n",
    "print(\"\\nğŸ¯ Observaciones:\")\n",
    "print(\"   â€¢ MÃ¡s iteraciones generalmente mejoran la calidad de la soluciÃ³n\")\n",
    "print(\"   â€¢ La tasa de mejora disminuye con mÃ¡s iteraciones (ley de rendimientos decrecientes)\")\n",
    "print(\"   â€¢ El tiempo de ejecuciÃ³n es prÃ¡cticamente lineal con el nÃºmero de iteraciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3082049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 10: Ejemplo interactivo personalizable\n",
    "print(\"ğŸ® EJEMPLO INTERACTIVO: Personaliza tu bÃºsqueda\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# FunciÃ³n personalizable por el usuario\n",
    "print(\"Puedes modificar estos parÃ¡metros directamente en el cÃ³digo:\")\n",
    "print()\n",
    "\n",
    "# ParÃ¡metros personalizables\n",
    "# Cambia estos valores para experimentar\n",
    "mi_funcion_str = \"x**3 - 6*x**2 + 9*x + 1\"  # Cambia esta expresiÃ³n\n",
    "mi_intervalo_a = -1  # Cambia el lÃ­mite inferior\n",
    "mi_intervalo_b = 5   # Cambia el lÃ­mite superior\n",
    "mis_iteraciones = 1200  # Cambia el nÃºmero de iteraciones\n",
    "buscar_maximo = False   # Cambia a True para buscar mÃ¡ximo\n",
    "\n",
    "print(f\"ğŸ“ FunciÃ³n personalizada: f(x) = {mi_funcion_str}\")\n",
    "print(f\"ğŸ“ Intervalo: [{mi_intervalo_a}, {mi_intervalo_b}]\")\n",
    "print(f\"ğŸ”„ Iteraciones: {mis_iteraciones}\")\n",
    "print(f\"ğŸ¯ Tipo de bÃºsqueda: {'MÃ¡ximo' if buscar_maximo else 'MÃ­nimo'}\")\n",
    "print()\n",
    "\n",
    "# Crear funciÃ³n a partir del string\n",
    "def mi_funcion_personalizada(x):\n",
    "    \"\"\"FunciÃ³n definida por el usuario\"\"\"\n",
    "    return eval(mi_funcion_str)\n",
    "\n",
    "try:\n",
    "    # Ejecutar bÃºsqueda personalizada\n",
    "    x_personal, f_personal, tabla_personal, stats_personal = random_search(\n",
    "        func=mi_funcion_personalizada,\n",
    "        a=mi_intervalo_a,\n",
    "        b=mi_intervalo_b,\n",
    "        n_iter=mis_iteraciones,\n",
    "        find_max=buscar_maximo,\n",
    "        semilla=789,\n",
    "        mostrar_progreso=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ“Š Ãšltimas 15 iteraciones de tu bÃºsqueda personalizada:\")\n",
    "    print(tabla_personal.tail(15))\n",
    "    \n",
    "    # Visualizar resultado personalizado\n",
    "    print(\"\\nğŸ“ˆ VisualizaciÃ³n de tu funciÃ³n personalizada:\")\n",
    "    graficar_resultados(mi_funcion_personalizada, x_personal, f_personal, \n",
    "                       tabla_personal, stats_personal, mostrar_todas_iteraciones=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error en la funciÃ³n personalizada: {e}\")\n",
    "    print(\"ğŸ’¡ Verifica que la expresiÃ³n matemÃ¡tica sea vÃ¡lida en Python\")\n",
    "    print(\"   Ejemplos vÃ¡lidos: 'x**2 + 3*x - 1', 'np.sin(x) + np.cos(2*x)', 'x**3 - 2*x'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0595e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 11: Resumen final y recomendaciones\n",
    "print(\"ğŸ“‹ RESUMEN FINAL Y RECOMENDACIONES\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"ğŸ¯ Â¿CuÃ¡ndo usar bÃºsqueda aleatoria?\")\n",
    "print(\"   âœ… Funciones no diferenciables o con discontinuidades\")\n",
    "print(\"   âœ… OptimizaciÃ³n global en funciones multimodales\")\n",
    "print(\"   âœ… Cuando no se requiere alta precisiÃ³n\")\n",
    "print(\"   âœ… Como mÃ©todo de inicializaciÃ³n para otros algoritmos\")\n",
    "print(\"   âœ… Funciones con ruido o incertidumbre\")\n",
    "print()\n",
    "\n",
    "print(\"âš ï¸  Limitaciones de la bÃºsqueda aleatoria:\")\n",
    "print(\"   âŒ Convergencia lenta comparada con mÃ©todos basados en gradientes\")\n",
    "print(\"   âŒ No garantiza encontrar el Ã³ptimo global\")\n",
    "print(\"   âŒ Requiere muchas evaluaciones de funciÃ³n\")\n",
    "print(\"   âŒ Eficiencia disminuye en espacios de alta dimensionalidad\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ”§ Recomendaciones para mejorar el rendimiento:\")\n",
    "print(\"   ğŸ’¡ Usa al menos 1000 iteraciones para funciones complejas\")\n",
    "print(\"   ğŸ’¡ Define intervalos de bÃºsqueda lo mÃ¡s pequeÃ±os posible\")\n",
    "print(\"   ğŸ’¡ Combina con bÃºsqueda local refinada (ej: gradiente descendente)\")\n",
    "print(\"   ğŸ’¡ Usa mÃºltiples ejecuciones con diferentes semillas\")\n",
    "print(\"   ğŸ’¡ Considera mÃ©todos hÃ­bridos para mejor eficiencia\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ§® Complejidad computacional:\")\n",
    "print(\"   â€¢ Tiempo: O(n) donde n = nÃºmero de iteraciones\")\n",
    "print(\"   â€¢ Espacio: O(n) para almacenar historial (opcional)\")\n",
    "print(\"   â€¢ Escalabilidad: Lineal con el nÃºmero de evaluaciones\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“š Extensiones posibles:\")\n",
    "print(\"   ğŸ”¹ BÃºsqueda aleatoria adaptativa (ajustar intervalo dinÃ¡micamente)\")\n",
    "print(\"   ğŸ”¹ BÃºsqueda aleatoria con memoria (evitar regiones ya exploradas)\")\n",
    "print(\"   ğŸ”¹ BÃºsqueda aleatoria multi-objetivo\")\n",
    "print(\"   ğŸ”¹ ParalelizaciÃ³n para mÃºltiples nÃºcleos\")\n",
    "print(\"   ğŸ”¹ IntegraciÃ³n con algoritmos evolutivos\")\n",
    "print()\n",
    "\n",
    "print(\"âœ¨ Â¡Felicidades! Has completado el tutorial de bÃºsqueda aleatoria.\")\n",
    "print(\"   Ahora puedes aplicar este mÃ©todo a tus propios problemas de optimizaciÃ³n.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
